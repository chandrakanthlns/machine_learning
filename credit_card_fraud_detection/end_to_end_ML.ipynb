{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./credit_card.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinctCounter = data.apply(lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = data.copy().drop(['Class'],axis=1)\n",
    "dataY = data['Class'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARDIZE THE FEATURE MATRIX X\n",
    "featuresToScale  = dataX.drop(['Time'],axis=1).columns\n",
    "sX = pp.StandardScaler(copy=True)\n",
    "dataX.loc[:,featuresToScale] = sX.fit_transform(dataX[featuresToScale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11',\n",
       "       'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n",
       "       'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresToScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering and Feature Selection\n",
    "# check for corelation\n",
    "correlationmatrix = pd.DataFrame(data=[] , index= dataX.columns , columns=dataX.columns)\n",
    "for i in dataX.columns:\n",
    "    for j in dataX.columns:\n",
    "        correlationmatrix.loc[i,j] = np.round(pearsonr(dataX.loc[:,i],dataX.loc[:,j])[0],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Preparation\n",
    "X_train,X_test,y_train,y_test = train_test_split(dataX,dataY,test_size = 0.33,random_state=2018,stratify=dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Cost Function\n",
    "# create kfold cross validation \n",
    "k_fold = StratifiedKFold(n_splits=5,shuffle=True,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine learning model\n",
    "# Logistic regression\n",
    "penalty = 'l2'\n",
    "C = 1.0\n",
    "class_weight = 'balanced'\n",
    "random_state = 2018\n",
    "solver = 'liblinear'\n",
    "n_jobs= -1\n",
    "\n",
    "logreg = LogisticRegression(C=C,penalty=penalty,class_weight=class_weight,random_state=random_state,\n",
    "                           solver=solver,n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrakanth\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.10966474080940092\n",
      "CV Log Loss:  0.10878960397277329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrakanth\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.10455317324268137\n",
      "CV Log Loss:  0.10403118930248074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrakanth\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.11556339731140397\n",
      "CV Log Loss:  0.11792747204693946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrakanth\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.11558629908146774\n",
      "CV Log Loss:  0.11817037719818489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\chandrakanth\\anaconda3\\envs\\deeplearn\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 4.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Log Loss:  0.09738511942742509\n",
      "CV Log Loss:  0.09720971197185728\n",
      "Logistic Regression Log Loss:  0.10922567089844716\n"
     ]
    }
   ],
   "source": [
    "trainingScores =[]\n",
    "cvScores = []\n",
    "predictionsBasedOnKFolds = pd.DataFrame(data=[],index=y_train.index,columns=[0,1])\n",
    "\n",
    "model = logreg\n",
    "for train_index, cv_index in k_fold.split(np.zeros(len(X_train))\n",
    "                                          ,y_train.ravel()):\n",
    "    X_train_fold , X_cv_fold  = X_train.iloc[train_index,:],X_train.iloc[cv_index,:]\n",
    "    y_train_fold, y_cv_fold = y_train.iloc[train_index], y_train.iloc[cv_index]    \n",
    "    model.fit(X_train_fold,y_train_fold)\n",
    "    loglossTraining = log_loss(y_train_fold,model.predict_proba(X_train_fold)[:,1])\n",
    "    trainingScores.append(loglossTraining)\n",
    "    predictionsBasedOnKFolds.loc[X_cv_fold.index,:] = model.predict_proba(X_cv_fold)\n",
    "    loglossCV = log_loss(y_cv_fold,predictionsBasedOnKFolds.loc[X_cv_fold.index,1])\n",
    "    cvScores.append(loglossCV)\n",
    "    print('Training Log Loss: ', loglossTraining)\n",
    "    print('CV Log Loss: ', loglossCV)\n",
    "\n",
    "loglossLogisticRegression = log_loss(y_train,predictionsBasedOnKFolds.loc[:,1])\n",
    "                                     \n",
    "print('Logistic Regression Log Loss: ', loglossLogisticRegression)\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Precision-Recall curve: Average Precision = 0.74')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluation metric\n",
    "preds = pd.concat([y_train,predictionsBasedOnKFolds.loc[:,1]], axis=1)\n",
    "preds.columns = ['trueLabel','prediction']\n",
    "predictionsBasedOnKFoldsLogisticRegression = preds.copy()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(preds['trueLabel'],\n",
    "                                                       preds['prediction'])\n",
    "\n",
    "average_precision = average_precision_score(preds['trueLabel'],\n",
    "                                            preds['prediction'])\n",
    "\n",
    "plt.step(recall, precision, color='k', alpha=0.7, where='post')\n",
    "plt.fill_between(recall, precision, step='post', alpha=0.3, color='k')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "\n",
    "plt.title('Precision-Recall curve: Average Precision = {0:0.2f}'.format(\n",
    "          average_precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
